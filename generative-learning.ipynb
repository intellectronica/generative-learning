{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgODZfKiBJdM"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade python-dotenv nest_asyncio pydantic google-genai requests pandas pyyaml\n",
    "\n",
    "from IPython.display import clear_output ; clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "from textwrap import dedent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import yaml\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "_gemini_client_aio = genai.Client(api_key=os.getenv('GEMINI_API_KEY')).aio\n",
    "\n",
    "G25PRO = 'gemini-2.5-pro-preview-03-25'\n",
    "G25FLASH = 'gemini-2.5-flash-preview-04-17'\n",
    "\n",
    "async def gemini(\n",
    "        prompt,\n",
    "        pro = False, max_tokens = None, temperature = None,\n",
    "        budget = None, schema = None):\n",
    "    config = {}\n",
    "    if max_tokens is not None:\n",
    "        config['max_output_tokens'] = max_tokens\n",
    "    if temperature is not None:\n",
    "        config['temperature'] = temperature\n",
    "    if budget is not None:\n",
    "        config['thinking_config'] = {'thinking_budget': budget}\n",
    "    if schema is not None:\n",
    "        config['response_mime_type'] = 'application/json'\n",
    "        config['response_schema'] = schema\n",
    "    \n",
    "    response = await _gemini_client_aio.models.generate_content(\n",
    "        model=(G25PRO if pro else G25FLASH),\n",
    "        contents=prompt,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    if schema is not None:\n",
    "        return response.parsed\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "def md(str): display(Markdown(str))\n",
    "\n",
    "def display_df(df):\n",
    "    display(df.style.set_properties(\n",
    "        **{'text-align': 'left', 'vertical-align': 'top', 'white-space': 'pre-wrap', 'width': '50%'},\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "\n",
    "display_df(dataset.head(3))\n",
    "\n",
    "print(f'{len(dataset)} items in dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset.iloc[:25].reset_index(drop=True)\n",
    "validation_dataset = dataset.iloc[25:50].reset_index(drop=True)\n",
    "testing_dataset = dataset.iloc[50:100].reset_index(drop=True)\n",
    "\n",
    "print(f'training: {training_dataset.shape}')\n",
    "display_df(training_dataset.tail(1))\n",
    "\n",
    "print(f'validation: {validation_dataset.shape}')\n",
    "display_df(validation_dataset.tail(1))\n",
    "\n",
    "print(f'testing: {testing_dataset.shape}')\n",
    "display_df(testing_dataset.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(res1, res2):\n",
    "    try:\n",
    "        return yaml.safe_load(res1) == yaml.safe_load(res2)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "async def discover_prompt(training_dataset, validation_dataset):\n",
    "    epochs = []\n",
    "    run_again = True\n",
    "\n",
    "    while run_again:\n",
    "        print(f'Epoch {len(epochs) + 1}\\n\\n')\n",
    "\n",
    "        epoch_prompt = None\n",
    "\n",
    "        training_sample_prompt = '<training-samples>\\n'\n",
    "        for i, row in training_dataset.iterrows():\n",
    "            training_sample_prompt += (\n",
    "                \"<sample>\\n\"\n",
    "                \"<input>\\n\"\n",
    "                + str(row['input']) + \"\\n\"\n",
    "                \"</input>\\n\"\n",
    "                \"<output>\\n\"\n",
    "                + str(row['output']) + \"\\n\"\n",
    "                \"</output>\\n\"\n",
    "                \"</sample>\\n\"\n",
    "            )\n",
    "        training_sample_prompt += '</training-samples>'\n",
    "        training_sample_prompt = dedent(training_sample_prompt)\n",
    "\n",
    "        if len(epochs) == 0:\n",
    "            epoch_prompt = dedent(f\"\"\"\n",
    "            You are an expert AI engineer.\n",
    "            Your goal is to create the most accurate and effective prompt for an LLM.\n",
    "            Below you are provided with a set of training samples.\n",
    "            Each samples consists of an input and an output.\n",
    "            You should create a prompt that will generate the output given the input.\n",
    "\n",
    "            Instructions: thinking carefully about the training samples to understand the exact transformation required.\n",
    "            Output: output only the generated prompt, without any additional text or structure (no quoting, no JSON, no XML, etc...)\n",
    "\n",
    "            {training_sample_prompt}\n",
    "            \"\"\")\n",
    "        else:\n",
    "            epoch_prompt = dedent(f\"\"\"\n",
    "            You are an expert AI engineer.\n",
    "            Your goal is to create the most accurate and effective prompt for an LLM.\n",
    "            Below you are provided with a set of training samples.\n",
    "            Each samples consists of an input and an output.\n",
    "            You should create a prompt that will generate the output given the input.\n",
    "\n",
    "            Instructions: thinking carefully about the training samples to understand the exact transformation required.\n",
    "            Output: output only the generated prompt, without any additional text or structure (no quoting, no JSON, no XML, etc...)\n",
    "\n",
    "            You have information about the previous training epochs:\n",
    "            <previous-epochs>\n",
    "            {json.dumps(epochs)}\n",
    "            <previous-epochs>\n",
    "\n",
    "            You need to improve the prompt.\n",
    "            Remember that you can rewrite the prompt completely if needed -\n",
    "            the previous prompt is provided here for your review.\n",
    "            \n",
    "            {training_sample_prompt}\n",
    "        \"\"\")\n",
    "\n",
    "        transform_prompt = await gemini(epoch_prompt, budget=12345)\n",
    "\n",
    "        print(transform_prompt)\n",
    "\n",
    "        validation_prompts = []\n",
    "        expected = []\n",
    "        for _, row in validation_dataset.iterrows():\n",
    "            expected.append(str(row['output']))\n",
    "            validation_prompts.append(f\"\"\"{transform_prompt}\n",
    "\n",
    "            <input>\n",
    "            {str(row['input'])}\n",
    "            </input>\n",
    "            \"\"\")\n",
    "\n",
    "        results = await asyncio.gather(*(gemini(p) for p in validation_prompts))\n",
    "\n",
    "        validation_results = [\n",
    "            {'expected': exp, 'result': res, 'match': compare_responses(exp, res)}\n",
    "            for exp, res in zip(expected, results)\n",
    "        ]\n",
    "\n",
    "        validation_accuracy = sum([1 for r in validation_results if r['match']]) / len(validation_results)\n",
    "        epochs.append({\n",
    "            'epoch_number': len(epochs),\n",
    "            'prompt': transform_prompt,\n",
    "            'validation_accuracy': validation_accuracy,\n",
    "            'validation_results': validation_results\n",
    "        })                \n",
    "\n",
    "        print(f'New prompt:\\n---\\n{transform_prompt}\\n---\\n')\n",
    "        print(f\"Validation accuracy: {validation_accuracy:.2%}\\n---\\n\\n\")\n",
    "\n",
    "        run_again = len(epochs) <= 23 and epochs[-1]['validation_accuracy'] <= 0.9\n",
    "    return epochs[-1]['prompt'], epochs[-1]['validation_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_prompt, transform_validation_accuracy = await discover_prompt(training_dataset, validation_dataset)\n",
    "\n",
    "print(f\"Transform prompt:\\n---\\n{transform_prompt}\\n---\\n\")\n",
    "print(f\"Validation accuracy: {transform_validation_accuracy:.2%}\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgU/ZZ6QdPgJgsWA2PABSv",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
